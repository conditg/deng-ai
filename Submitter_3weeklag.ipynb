{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tools import eval_measures\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeats = pd.read_csv('data/dengue_features_train.csv')\n",
    "rawlabels = pd.read_csv('data/dengue_labels_train.csv')\n",
    "rawfeats['total_cases'] = rawlabels['total_cases']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Juan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(936, 25)\n"
     ]
    }
   ],
   "source": [
    "sj = rawfeats[rawfeats.city=='sj']\n",
    "print(sj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_SJ(rawfeats):\n",
    "    #Returns a dataset ready for splitting/training or prediction\n",
    "    #Fill nas with interpolation\n",
    "    feats = rawfeats.interpolate(method='linear')\n",
    "    #Replace week 53 with week 52\n",
    "    feats.loc[:,'weekofyear'] = np.where(feats.weekofyear > 52, 52, feats.weekofyear)\n",
    "    #Scale then average temperature readings\n",
    "    tempscols_to_average = feats.loc[:,['reanalysis_max_air_temp_k', 'station_avg_temp_c',\n",
    "       'reanalysis_avg_temp_k', 'reanalysis_min_air_temp_k',\n",
    "       'station_min_temp_c', 'reanalysis_dew_point_temp_k',\n",
    "       'reanalysis_air_temp_k']]\n",
    "    scaled_temps = pd.DataFrame(MinMaxScaler().fit_transform(tempscols_to_average), \n",
    "                            columns=tempscols_to_average.columns)\n",
    "    feats.loc[:,'temps_mean'] = scaled_temps.mean(axis=1)\n",
    "    #Boolean season variables\n",
    "    cutoffs = [11, 26, 42]\n",
    "    feats['winter'] = np.where((feats.weekofyear<cutoffs[0]), 1, 0)\n",
    "\n",
    "    feats['spring'] = np.where((feats.weekofyear>=cutoffs[0]) &\n",
    "                               (feats.weekofyear<cutoffs[1]), 1, 0)\n",
    "    feats['summer'] = np.where((feats.weekofyear>=cutoffs[1]) &\n",
    "                               (feats.weekofyear<cutoffs[2]), 1, 0)\n",
    "    feats['fall'] = np.where((feats.weekofyear>=cutoffs[2]), 1, 0)\n",
    "    #drop unneeded columns\n",
    "    keep = ['total_cases','spring', 'summer', 'fall', 'station_max_temp_c',\n",
    "       'temps_mean', 'reanalysis_relative_humidity_percent',\n",
    "       'reanalysis_specific_humidity_g_per_kg','reanalysis_precip_amt_kg_per_m2']\n",
    "    for col in feats.columns:\n",
    "        if col not in keep:\n",
    "            feats = feats.drop(col, axis=1)\n",
    "    \n",
    "    #add shifted feats, 3 weeks\n",
    "    to_shift = ['station_max_temp_c', 'temps_mean','reanalysis_relative_humidity_percent',\n",
    "       'reanalysis_specific_humidity_g_per_kg','reanalysis_precip_amt_kg_per_m2']\n",
    "    \n",
    "    for i in to_shift:\n",
    "        feats[i+'_1lag'] = feats[i].shift(-1)\n",
    "        feats[i+'_2lag'] = feats[i].shift(-2)\n",
    "        feats[i+'_3lag'] = feats[i].shift(-3)\n",
    "    feats = feats.fillna(method='ffill')\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(936, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj = process_SJ(sj)\n",
    "sj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(655, 23)\n",
      "(281, 23)\n"
     ]
    }
   ],
   "source": [
    "#Split\n",
    "sj_X = sj.drop(['total_cases'], axis=1)\n",
    "sj_y = sj.total_cases\n",
    "\n",
    "X_train_sj, X_test_sj, y_train_sj, y_test_sj = train_test_split(\n",
    "    sj_X, sj_y, test_size=0.3)\n",
    "print(X_train_sj.shape)\n",
    "print(X_test_sj.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iquitos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520, 25)\n"
     ]
    }
   ],
   "source": [
    "iq = rawfeats[rawfeats.city=='iq']\n",
    "print(iq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_IQ(rawfeats):\n",
    "    #Returns a dataset ready for splitting/training or prediction\n",
    "    #Fill nas with interpolation\n",
    "    feats = rawfeats.interpolate(method='linear')\n",
    "    #Replace week 53 with week 52\n",
    "    feats.loc[:,'weekofyear'] = np.where(feats.weekofyear > 52, 52, feats.weekofyear)\n",
    "    #season features\n",
    "    cutoffs = [15, 31, 46]\n",
    "    feats['fall'] = np.where((feats.weekofyear<cutoffs[0]), 1, 0)\n",
    "\n",
    "    feats['winter'] = np.where((feats.weekofyear>=cutoffs[0]) &\n",
    "                               (feats.weekofyear<cutoffs[1]), 1, 0)\n",
    "    feats['spring'] = np.where((feats.weekofyear>=cutoffs[1]) &\n",
    "                               (feats.weekofyear<cutoffs[2]), 1, 0)\n",
    "    feats['summer'] = np.where((feats.weekofyear>=cutoffs[2]), 1, 0)\n",
    "    #drop unneeded columns\n",
    "    keep = ['total_cases',\n",
    "       'spring', 'summer', 'fall', 'station_avg_temp_c',\n",
    "       'reanalysis_min_air_temp_k','station_min_temp_c',\n",
    "       'reanalysis_dew_point_temp_k','reanalysis_tdtr_k',\n",
    "       'reanalysis_specific_humidity_g_per_kg',\n",
    "       'precipitation_amt_mm']\n",
    "    \n",
    "    for col in feats.columns:\n",
    "        if col not in keep:\n",
    "            feats = feats.drop(col, axis=1)\n",
    "    \n",
    "    #add shifted feats, 3 weeks\n",
    "    to_shift = ['station_avg_temp_c','reanalysis_min_air_temp_k', 'station_min_temp_c',\n",
    "       'reanalysis_dew_point_temp_k', 'reanalysis_tdtr_k', \n",
    "       'reanalysis_specific_humidity_g_per_kg','precipitation_amt_mm']\n",
    "    \n",
    "    for i in to_shift:\n",
    "        feats[i+'_1lag'] = feats[i].shift(-1)\n",
    "        feats[i+'_2lag'] = feats[i].shift(-2)\n",
    "        feats[i+'_3lag'] = feats[i].shift(-3)\n",
    "    feats = feats.fillna(method='ffill')\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq = process_IQ(iq)\n",
    "iq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_X = iq.drop(['total_cases'], axis=1)\n",
    "#X2 = iqshiftedfeats.drop(['total_cases', 'city', 'year', 'weekofyear'], axis=1) #for regularizing techniques\n",
    "iq_y = iq.total_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 31)\n",
      "(156, 31)\n"
     ]
    }
   ],
   "source": [
    "X_train_iq, X_test_iq, y_train_iq, y_test_iq = train_test_split(\n",
    "    iq_X, iq_y, test_size=0.3)\n",
    "print(X_train_iq.shape)\n",
    "print(X_test_iq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Searched Random Forest Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the parameters we want to cycle through\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [5,10,20,30,40,50],\n",
    "    'max_features': [2, 5, 'auto'],\n",
    "    'min_samples_leaf': [2, 3, 4],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'n_estimators': [100, 300, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfr = RandomForestRegressor()\n",
    "# gs = GridSearchCV(estimator=rfr, param_grid=param_grid,cv=3, n_jobs=-1)\n",
    "\n",
    "# #Fit the grid search to data for SJ\n",
    "# gs.fit(X_train_sj, y_train_sj)\n",
    "\n",
    "# #Let's see what came out best:\n",
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_rf_params = {'bootstrap': True,\n",
    " 'max_depth': 40,\n",
    " 'max_features': 5,\n",
    " 'min_samples_leaf': 3,\n",
    " 'min_samples_split': 2,\n",
    " 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfr = RandomForestRegressor()\n",
    "# gs = GridSearchCV(estimator=rfr, param_grid=param_grid,cv=3, n_jobs=-1)\n",
    "\n",
    "# #Fit the grid search to data for SJ\n",
    "# gs.fit(X_train_iq, y_train_iq)\n",
    "\n",
    "# #Let's see what came out best:\n",
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_rf_params = {'bootstrap': True,\n",
    " 'max_depth': 20,\n",
    " 'max_features': 2,\n",
    " 'min_samples_leaf': 3,\n",
    " 'min_samples_split': 4,\n",
    " 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_rfr = RandomForestRegressor(**sj_rf_params)\n",
    "iq_rfr = RandomForestRegressor(**iq_rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
       "           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=3,\n",
       "           min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=None, oob_score=False,\n",
       "           random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_rfr.fit(sj_X, sj_y)\n",
    "iq_rfr.fit(iq_X, iq_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pd.read_csv('data/dengue_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 23)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_test = testdata[testdata.city=='sj'].copy()\n",
    "sj_test = process_SJ(sj_test)\n",
    "#23 feat columns\n",
    "sj_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 31)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_test = testdata[testdata.city=='iq'].copy()\n",
    "iq_test = process_IQ(iq_test)\n",
    "#31 feat columns\n",
    "iq_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_pred = sj_rfr.predict(sj_test).astype(int)\n",
    "iq_pred = iq_rfr.predict(iq_test).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#zero out negatives if applicable\n",
    "print(np.min(sj_pred))\n",
    "print(np.min(iq_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/submission_format.csv',\n",
    "                            index_col=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.total_cases = np.concatenate([sj_pred, iq_pred])\n",
    "submission.to_csv(\"rfr_with_3wk_lag.csv\")\n",
    "#This scored a 24.9, a point better than the benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  6,  4,  2,  2,  2,  2,  4,  4,  5,  3,  4,  3,  5,  6, 10, 10,\n",
       "       10, 10, 11, 14,  8,  9,  9,  8,  6,  7,  7,  5,  5,  5,  8, 13, 12,\n",
       "        9, 10, 11, 12, 11, 12,  8, 11,  8,  8,  5,  5,  5,  4,  3,  3,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  3,  3,  4,  3,  4,  5,  5,  6,  8,  8,\n",
       "        9,  9, 11, 12, 10, 11, 11, 10, 13, 12,  9,  7,  7,  8,  9,  8,  8,\n",
       "        7,  7,  5,  7,  6,  9, 11, 10,  9,  7,  7,  6,  5,  4,  3,  4,  3,\n",
       "        2,  3,  3,  3,  3,  3,  2,  3,  2,  2,  2,  2,  2,  2,  3,  5,  7,\n",
       "        7, 10, 10, 13, 14, 11, 12, 11, 12,  8,  7,  9,  8, 13,  9, 12,  8,\n",
       "       13, 13, 16, 16, 13, 12,  8, 11,  7,  8,  9,  8,  7,  6,  4,  4,  3,\n",
       "        3,  3,  4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Binomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_params = 10 ** np.arange(-8, -2, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total_cases ~ reanalysis_precip_amt_kg_per_m2 + reanalysis_relative_humidity_percent + reanalysis_specific_humidity_g_per_kg + station_max_temp_c + temps_mean + spring + summer + fall + station_max_temp_c_1lag + station_max_temp_c_2lag + station_max_temp_c_3lag + temps_mean_1lag + temps_mean_2lag + temps_mean_3lag + reanalysis_relative_humidity_percent_1lag + reanalysis_relative_humidity_percent_2lag + reanalysis_relative_humidity_percent_3lag + reanalysis_specific_humidity_g_per_kg_1lag + reanalysis_specific_humidity_g_per_kg_2lag + reanalysis_specific_humidity_g_per_kg_3lag + reanalysis_precip_amt_kg_per_m2_1lag + reanalysis_precip_amt_kg_per_m2_2lag + reanalysis_precip_amt_kg_per_m2_3lag'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create statsmodels formula\n",
    "formula = 'total_cases ~ '\n",
    "for i in sj.columns:\n",
    "    if i != 'total_cases':\n",
    "        formula = formula + str(i) + ' + '\n",
    "formula =  formula[:-3] #trim the last plus sign\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha =  0.001\n",
      "best score =  24.085409252669038\n"
     ]
    }
   ],
   "source": [
    "sjtrain, sjtest, _, _ = train_test_split(\n",
    "    sj, [0 for _ in range(sj.shape[0])], test_size=0.3)\n",
    "for alpha in grid:\n",
    "    model = smf.glm(formula=formula, data=sjtrain,\n",
    "                    family=sm.families.NegativeBinomial(alpha=alpha))\n",
    "    results = model.fit()\n",
    "    predictions = results.predict(sjtest).astype(int)\n",
    "    score = eval_measures.meanabs(predictions, sjtest.total_cases)\n",
    "    best_score = 1000\n",
    "    if score < best_score:\n",
    "        best_alpha = alpha\n",
    "        best_score = score\n",
    "print('best alpha = ', best_alpha)\n",
    "print('best score = ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.glm(formula=formula, data=sj, \n",
    "               family=sm.families.NegativeBinomial(alpha=best_alpha))\n",
    "\n",
    "results = model.fit()\n",
    "sj_pred = results.predict(sj_test).astype(int)\n",
    "#confirm no negatives\n",
    "np.min(sj_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total_cases ~ precipitation_amt_mm + reanalysis_dew_point_temp_k + reanalysis_min_air_temp_k + reanalysis_specific_humidity_g_per_kg + reanalysis_tdtr_k + station_avg_temp_c + station_min_temp_c + fall + spring + summer + station_avg_temp_c_1lag + station_avg_temp_c_2lag + station_avg_temp_c_3lag + reanalysis_min_air_temp_k_1lag + reanalysis_min_air_temp_k_2lag + reanalysis_min_air_temp_k_3lag + station_min_temp_c_1lag + station_min_temp_c_2lag + station_min_temp_c_3lag + reanalysis_dew_point_temp_k_1lag + reanalysis_dew_point_temp_k_2lag + reanalysis_dew_point_temp_k_3lag + reanalysis_tdtr_k_1lag + reanalysis_tdtr_k_2lag + reanalysis_tdtr_k_3lag + reanalysis_specific_humidity_g_per_kg_1lag + reanalysis_specific_humidity_g_per_kg_2lag + reanalysis_specific_humidity_g_per_kg_3lag + precipitation_amt_mm_1lag + precipitation_amt_mm_2lag + precipitation_amt_mm_3lag'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create statsmodels formula\n",
    "formula = 'total_cases ~ '\n",
    "for i in iq.columns:\n",
    "    if i != 'total_cases':\n",
    "        formula = formula + str(i) + ' + '\n",
    "formula =  formula[:-3] #trim the last plus sign\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha =  0.001\n",
      "best score =  6.538461538461538\n"
     ]
    }
   ],
   "source": [
    "iqtrain, iqtest, _, _ = train_test_split(\n",
    "    iq, [0 for _ in range(iq.shape[0])], test_size=0.3)\n",
    "for alpha in grid:\n",
    "    model = smf.glm(formula=formula, data=iqtrain,\n",
    "                    family=sm.families.NegativeBinomial(alpha=alpha))\n",
    "    results = model.fit()\n",
    "    predictions = results.predict(iqtest).astype(int)\n",
    "    score = eval_measures.meanabs(predictions, iqtest.total_cases)\n",
    "    best_score = 1000\n",
    "    if score < best_score:\n",
    "        best_alpha = alpha\n",
    "        best_score = score\n",
    "print('best alpha = ', best_alpha)\n",
    "print('best score = ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.glm(formula=formula, data=iq, \n",
    "               family=sm.families.NegativeBinomial(alpha=best_alpha))\n",
    "\n",
    "results = model.fit()\n",
    "iq_pred = results.predict(iq_test).astype(int)\n",
    "#confirm no negatives\n",
    "np.min(iq_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('submission_format.csv',\n",
    "                            index_col=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.total_cases = np.concatenate([sj_pred, iq_pred])\n",
    "submission.to_csv(\"NBR_with_3wk_lag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
