{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tools import eval_measures\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeats = pd.read_csv('dengue_features_train.csv')\n",
    "rawlabels = pd.read_csv('dengue_labels_train.csv')\n",
    "rawfeats['total_cases'] = rawlabels['total_cases']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Juan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(936, 25)\n"
     ]
    }
   ],
   "source": [
    "sj = rawfeats[rawfeats.city=='sj']\n",
    "print(sj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_SJ(rawfeats):\n",
    "    #Returns a dataset ready for splitting/training or prediction\n",
    "    #Fill nas with interpolation\n",
    "    feats = rawfeats.interpolate(method='linear')\n",
    "    #Replace week 53 with week 52\n",
    "    feats.loc[:,'weekofyear'] = np.where(feats.weekofyear > 52, 52, feats.weekofyear)\n",
    "    #Scale then average temperature readings\n",
    "    tempscols_to_average = feats.loc[:,['reanalysis_max_air_temp_k', 'station_avg_temp_c',\n",
    "       'reanalysis_avg_temp_k', 'reanalysis_min_air_temp_k',\n",
    "       'station_min_temp_c', 'reanalysis_dew_point_temp_k',\n",
    "       'reanalysis_air_temp_k']]\n",
    "    scaled_temps = pd.DataFrame(MinMaxScaler().fit_transform(tempscols_to_average), \n",
    "                            columns=tempscols_to_average.columns)\n",
    "    feats.loc[:,'temps_mean'] = scaled_temps.mean(axis=1)\n",
    "    #Boolean season variables\n",
    "    cutoffs = [11, 26, 42]\n",
    "    feats['winter'] = np.where((feats.weekofyear<cutoffs[0]), 1, 0)\n",
    "\n",
    "    feats['spring'] = np.where((feats.weekofyear>=cutoffs[0]) &\n",
    "                               (feats.weekofyear<cutoffs[1]), 1, 0)\n",
    "    feats['summer'] = np.where((feats.weekofyear>=cutoffs[1]) &\n",
    "                               (feats.weekofyear<cutoffs[2]), 1, 0)\n",
    "    feats['fall'] = np.where((feats.weekofyear>=cutoffs[2]), 1, 0)\n",
    "    #drop unneeded columns\n",
    "    keep = ['total_cases','spring', 'summer', 'fall', 'station_max_temp_c',\n",
    "       'temps_mean', 'reanalysis_relative_humidity_percent',\n",
    "       'reanalysis_specific_humidity_g_per_kg','reanalysis_precip_amt_kg_per_m2']\n",
    "    for col in feats.columns:\n",
    "        if col not in keep:\n",
    "            feats = feats.drop(col, axis=1)\n",
    "    \n",
    "    #add moving average, 3 weeks\n",
    "    to_shift = ['station_max_temp_c', 'temps_mean','reanalysis_relative_humidity_percent',\n",
    "       'reanalysis_specific_humidity_g_per_kg','reanalysis_precip_amt_kg_per_m2']\n",
    "    \n",
    "    for i in to_shift:\n",
    "        feats[i+'_3wkavg'] = feats.rolling(window=3)[i].mean()\n",
    "    feats = feats.fillna(method='bfill')\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(936, 14)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj = process_SJ(sj)\n",
    "sj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(655, 13)\n",
      "(281, 13)\n"
     ]
    }
   ],
   "source": [
    "#Split\n",
    "sj_X = sj.drop(['total_cases'], axis=1)\n",
    "sj_y = sj.total_cases\n",
    "\n",
    "X_train_sj, X_test_sj, y_train_sj, y_test_sj = train_test_split(\n",
    "    sj_X, sj_y, test_size=0.3)\n",
    "print(X_train_sj.shape)\n",
    "print(X_test_sj.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iquitos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520, 25)\n"
     ]
    }
   ],
   "source": [
    "iq = rawfeats[rawfeats.city=='iq']\n",
    "print(iq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_IQ(rawfeats):\n",
    "    #Returns a dataset ready for splitting/training or prediction\n",
    "    #Fill nas with interpolation\n",
    "    feats = rawfeats.interpolate(method='linear')\n",
    "    #Replace week 53 with week 52\n",
    "    feats.loc[:,'weekofyear'] = np.where(feats.weekofyear > 52, 52, feats.weekofyear)\n",
    "    #season features\n",
    "    cutoffs = [15, 31, 46]\n",
    "    feats['fall'] = np.where((feats.weekofyear<cutoffs[0]), 1, 0)\n",
    "\n",
    "    feats['winter'] = np.where((feats.weekofyear>=cutoffs[0]) &\n",
    "                               (feats.weekofyear<cutoffs[1]), 1, 0)\n",
    "    feats['spring'] = np.where((feats.weekofyear>=cutoffs[1]) &\n",
    "                               (feats.weekofyear<cutoffs[2]), 1, 0)\n",
    "    feats['summer'] = np.where((feats.weekofyear>=cutoffs[2]), 1, 0)\n",
    "    #drop unneeded columns\n",
    "    keep = ['total_cases',\n",
    "       'spring', 'summer', 'fall', 'station_avg_temp_c',\n",
    "       'reanalysis_min_air_temp_k','station_min_temp_c',\n",
    "       'reanalysis_dew_point_temp_k','reanalysis_tdtr_k',\n",
    "       'reanalysis_specific_humidity_g_per_kg',\n",
    "       'precipitation_amt_mm']\n",
    "    \n",
    "    for col in feats.columns:\n",
    "        if col not in keep:\n",
    "            feats = feats.drop(col, axis=1)\n",
    "    \n",
    "    #add shifted feats, 3 weeks\n",
    "    to_shift = ['station_avg_temp_c','reanalysis_min_air_temp_k', 'station_min_temp_c',\n",
    "       'reanalysis_dew_point_temp_k', 'reanalysis_tdtr_k', \n",
    "       'reanalysis_specific_humidity_g_per_kg','precipitation_amt_mm']\n",
    "    \n",
    "    for i in to_shift:\n",
    "        feats[i+'_3wkavg'] = feats.rolling(window=3)[i].mean()\n",
    "    feats = feats.fillna(method='bfill')\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 18)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq = process_IQ(iq)\n",
    "iq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_X = iq.drop(['total_cases'], axis=1)\n",
    "#X2 = iqshiftedfeats.drop(['total_cases', 'city', 'year', 'weekofyear'], axis=1) #for regularizing techniques\n",
    "iq_y = iq.total_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 17)\n",
      "(156, 17)\n"
     ]
    }
   ],
   "source": [
    "X_train_iq, X_test_iq, y_train_iq, y_test_iq = train_test_split(\n",
    "    iq_X, iq_y, test_size=0.3)\n",
    "print(X_train_iq.shape)\n",
    "print(X_test_iq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Searched Random Forest Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the parameters we want to cycle through\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [5,10,20,30,40,50],\n",
    "    'max_features': [2, 5, 'auto'],\n",
    "    'min_samples_leaf': [2, 3, 4],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'n_estimators': [100, 300, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\greg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 30,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rfr = RandomForestRegressor()\n",
    "# gs = GridSearchCV(estimator=rfr, param_grid=param_grid,cv=3, n_jobs=-1)\n",
    "\n",
    "# #Fit the grid search to data for SJ\n",
    "# gs.fit(X_train_sj, y_train_sj)\n",
    "\n",
    "# #Let's see what came out best:\n",
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_rf_params = {'bootstrap': True,\n",
    " 'max_depth': 30,\n",
    " 'max_features': 'auto',\n",
    " 'min_samples_leaf': 2,\n",
    " 'min_samples_split': 4,\n",
    " 'n_estimators': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\greg\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 20,\n",
       " 'max_features': 2,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gs2 = GridSearchCV(estimator=rfr, param_grid=param_grid,cv=3, n_jobs=-1)\n",
    "\n",
    "# #Fit the grid search to data for IQ\n",
    "# gs2.fit(X_train_iq, y_train_iq)\n",
    "\n",
    "# #Let's see what came out best:\n",
    "# gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_rf_params = {'bootstrap': True,\n",
    " 'max_depth': 20,\n",
    " 'max_features': 2,\n",
    " 'min_samples_leaf': 3,\n",
    " 'min_samples_split': 4,\n",
    " 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_rfr = RandomForestRegressor(**sj_rf_params)\n",
    "iq_rfr = RandomForestRegressor(**iq_rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
       "           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=3,\n",
       "           min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=None, oob_score=False,\n",
       "           random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_rfr.fit(sj_X, sj_y)\n",
    "iq_rfr.fit(iq_X, iq_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pd.read_csv('dengue_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 13)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_test = testdata[testdata.city=='sj'].copy()\n",
    "sj_test = process_SJ(sj_test)\n",
    "#23 feat columns\n",
    "sj_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 17)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_test = testdata[testdata.city=='iq'].copy()\n",
    "iq_test = process_IQ(iq_test)\n",
    "#31 feat columns\n",
    "iq_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_pred = sj_rfr.predict(sj_test).astype(int)\n",
    "iq_pred = iq_rfr.predict(iq_test).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#zero out negatives if applicable\n",
    "print(np.min(sj_pred))\n",
    "print(np.min(iq_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('submission_format.csv',\n",
    "                            index_col=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.total_cases = np.concatenate([sj_pred, iq_pred])\n",
    "submission.to_csv(\"rfr_with_3wk_mean.csv\")\n",
    "#This scored a 26.1, a point better than the benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit this 3/11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Binomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_params = 10 ** np.arange(-8, -2, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total_cases ~ reanalysis_precip_amt_kg_per_m2 + reanalysis_relative_humidity_percent + reanalysis_specific_humidity_g_per_kg + station_max_temp_c + temps_mean + spring + summer + fall + station_max_temp_c_3wkavg + temps_mean_3wkavg + reanalysis_relative_humidity_percent_3wkavg + reanalysis_specific_humidity_g_per_kg_3wkavg + reanalysis_precip_amt_kg_per_m2_3wkavg'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create statsmodels formula\n",
    "formula = 'total_cases ~ '\n",
    "for i in sj.columns:\n",
    "    if i != 'total_cases':\n",
    "        formula = formula + str(i) + ' + '\n",
    "formula =  formula[:-3] #trim the last plus sign\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha =  0.001\n",
      "best score =  25.209964412811388\n"
     ]
    }
   ],
   "source": [
    "sjtrain, sjtest, _, _ = train_test_split(\n",
    "    sj, [0 for _ in range(sj.shape[0])], test_size=0.3)\n",
    "for alpha in alpha_params:\n",
    "    model = smf.glm(formula=formula, data=sjtrain,\n",
    "                    family=sm.families.NegativeBinomial(alpha=alpha))\n",
    "    results = model.fit()\n",
    "    predictions = results.predict(sjtest).astype(int)\n",
    "    score = eval_measures.meanabs(predictions, sjtest.total_cases)\n",
    "    best_score = 1000\n",
    "    if score < best_score:\n",
    "        best_alpha = alpha\n",
    "        best_score = score\n",
    "print('best alpha = ', best_alpha)\n",
    "print('best score = ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.glm(formula=formula, data=sj, \n",
    "               family=sm.families.NegativeBinomial(alpha=best_alpha))\n",
    "\n",
    "results = model.fit()\n",
    "sj_pred = results.predict(sj_test).astype(int)\n",
    "#confirm no negatives\n",
    "np.min(sj_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total_cases ~ precipitation_amt_mm + reanalysis_dew_point_temp_k + reanalysis_min_air_temp_k + reanalysis_specific_humidity_g_per_kg + reanalysis_tdtr_k + station_avg_temp_c + station_min_temp_c + fall + spring + summer + station_avg_temp_c_3wkavg + reanalysis_min_air_temp_k_3wkavg + station_min_temp_c_3wkavg + reanalysis_dew_point_temp_k_3wkavg + reanalysis_tdtr_k_3wkavg + reanalysis_specific_humidity_g_per_kg_3wkavg + precipitation_amt_mm_3wkavg'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create statsmodels formula\n",
    "formula = 'total_cases ~ '\n",
    "for i in iq.columns:\n",
    "    if i != 'total_cases':\n",
    "        formula = formula + str(i) + ' + '\n",
    "formula =  formula[:-3] #trim the last plus sign\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha =  0.001\n",
      "best score =  5.9423076923076925\n"
     ]
    }
   ],
   "source": [
    "iqtrain, iqtest, _, _ = train_test_split(\n",
    "    iq, [0 for _ in range(iq.shape[0])], test_size=0.3)\n",
    "for alpha in alpha_params:\n",
    "    model = smf.glm(formula=formula, data=iqtrain,\n",
    "                    family=sm.families.NegativeBinomial(alpha=alpha))\n",
    "    results = model.fit()\n",
    "    predictions = results.predict(iqtest).astype(int)\n",
    "    score = eval_measures.meanabs(predictions, iqtest.total_cases)\n",
    "    best_score = 1000\n",
    "    if score < best_score:\n",
    "        best_alpha = alpha\n",
    "        best_score = score\n",
    "print('best alpha = ', best_alpha)\n",
    "print('best score = ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.glm(formula=formula, data=iq, \n",
    "               family=sm.families.NegativeBinomial(alpha=best_alpha))\n",
    "\n",
    "results = model.fit()\n",
    "iq_pred = results.predict(iq_test).astype(int)\n",
    "#confirm no negatives\n",
    "np.min(iq_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('submission_format.csv',\n",
    "                            index_col=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.total_cases = np.concatenate([sj_pred, iq_pred])\n",
    "submission.to_csv(\"NBR_with_3wkmean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
